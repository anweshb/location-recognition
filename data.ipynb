{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6af7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04c768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Video Location Identification/Data/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'Val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "cities = ['paris', 'moscow', 'cairo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97eef1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frame_arrays(train_dir, frame_list):\n",
    "    \n",
    "    ##Function to store images as arrays given directory and filenames of images \n",
    "    \n",
    "    shape = (224,224)\n",
    "    \n",
    "    frame_arr = []\n",
    "    \n",
    "    for images in frame_list:\n",
    "        \n",
    "        img = Image.open(os.path.join(train_dir, images))\n",
    "        resized_image = np.array(img.resize(shape, Image.ANTIALIAS))\n",
    "        \n",
    "        frame_arr.append(resized_image)\n",
    "        \n",
    "    return np.array(frame_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e575d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify(arr, sequence_size):\n",
    "    if sequence_size <= 0:\n",
    "        raise ValueError(\"Sequence size must be a positive integer.\")\n",
    "\n",
    "    if len(arr) < sequence_size:\n",
    "        raise ValueError(\"Array size should be greater than or equal to the sequence size.\")\n",
    "\n",
    "    sequences = [arr[i:i + sequence_size] for i in range(len(arr) - sequence_size + 1)]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be050d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(path_dir, cities, data_seg):\n",
    "    \n",
    "    paris_dir = os.path.join(path_dir, cities[0])\n",
    "    moscow_dir = os.path.join(path_dir, cities[1])\n",
    "    cairo_dir = os.path.join(path_dir, cities[2])\n",
    "    \n",
    "    if data_seg == 'train':\n",
    "        frame_nums = [x for x in range(0,18000,30)]\n",
    "    \n",
    "    elif data_seg == 'val':\n",
    "        frame_nums = [x for x in range(0, 3000, 30)]\n",
    "    \n",
    "    elif data_seg == 'test':\n",
    "        frame_nums = [x for x in range(0, 6000, 30)]\n",
    "    else:\n",
    "        raise Exception(\"data_seg argument must be either 'train', 'val', or 'test'\")\n",
    "\n",
    "    \n",
    "    paris_frames = [cities[0]+'_frame'+str(x)+'.jpg' for x in frame_nums]\n",
    "    moscow_frames = [cities[1]+'_frame'+str(x)+'.jpg' for x in frame_nums]\n",
    "    cairo_frames = [cities[2]+'_frame'+str(x)+'.jpg' for x in frame_nums]\n",
    "    \n",
    "    paris = make_frame_arrays(paris_dir, paris_frames)\n",
    "    moscow = make_frame_arrays(moscow_dir, moscow_frames)\n",
    "    cairo = make_frame_arrays(cairo_dir, cairo_frames)\n",
    "    \n",
    "    paris_seq = np.array(sequencify(paris, 10))\n",
    "    moscow_seq = np.array(sequencify(moscow, 10))\n",
    "    cairo_seq = np.array(sequencify(cairo, 10))\n",
    "    \n",
    "    paris_labels = np.zeros(len(paris_seq))\n",
    "    moscow_labels = np.ones(len(moscow_seq))\n",
    "    cairo_labels = np.dot(np.ones(len(cairo_seq)), 2)\n",
    "    \n",
    "    features = np.vstack((np.vstack((paris_seq, moscow_seq)), cairo_seq))\n",
    "    labels = np.hstack((np.hstack((paris_labels, moscow_labels)), cairo_labels))\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdcb775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.3568821.pbshpc/ipykernel_10689/453982518.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_image = np.array(img.resize(shape, Image.ANTIALIAS))\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = make_dataset(train_dir, cities, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82920823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.3568821.pbshpc/ipykernel_10689/453982518.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_image = np.array(img.resize(shape, Image.ANTIALIAS))\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = make_dataset(val_dir, cities, 'val')\n",
    "x_test, y_test = make_dataset(test_dir, cities, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f398cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train.npy', x_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "np.save('x_val.npy', x_val)\n",
    "np.save('y_val.npy', y_val)\n",
    "\n",
    "np.save('x_test.npy', x_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7dbfba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
